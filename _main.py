import asyncio
import streamlit as st
from openai_gpt import gpt_prompt
from google_gemini import gemini_prompt
from anthropic_claude import claude_prompt
from meta_llama import llama_prompt

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(layout="wide")

# ìœ ì €ì˜ promptë¥¼ stateì— ì €ì¥
prompt = st.chat_input("í”„ë¡¬í”„íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
st.session_state["prompt"] = prompt


# ë¹„ë™ê¸° API í˜¸ì¶œ í•¨ìˆ˜ ì •ì˜
async def fetch_gpt_response(prompt):
    return gpt_prompt(prompt) if prompt else "gpt-4o-mini"


async def fetch_gemini_response(prompt):
    return gemini_prompt(prompt) if prompt else "Gemini-1.5-flash"


async def fetch_claude_response(prompt):
    return claude_prompt(prompt) if prompt else "Claude-3-5-sonnet"


async def fetch_llama_response(prompt):
    return llama_prompt(prompt) if prompt else "Llama3.2-90b-vision"


# ë¹„ë™ê¸° ì²˜ë¦¬ í•¨ìˆ˜
async def fetch_all_responses(prompt):
    responses = await asyncio.gather(
        fetch_gpt_response(prompt),
        fetch_gemini_response(prompt),
        fetch_claude_response(prompt),
        fetch_llama_response(prompt),
    )
    return responses


# ë¹„ë™ê¸° ì‘ë‹µ ë°›ì•„ì˜¤ê¸°
responses = asyncio.run(fetch_all_responses(prompt))

# íƒ­ êµ¬ì„±
All, gpt_as_tab, gemini_as_tab, claude_as_tab, llama_as_tab = st.tabs(
    ["ì „ì²´", "chatGPT", "Gemini", "Claude", "llama"]
)

# íƒ­: ì „ì²´
with All:
    gpt_as_col, gemini_as_col, claude_as_col, llama_as_col = st.columns(4)

    with gpt_as_col:
        with st.chat_message("ai", avatar="./assets/gpt.svg"):
            st.markdown("**openAI: gpt-4o-mini**")
            st.write(responses[0])  # GPT ì‘ë‹µ

    with gemini_as_col:
        with st.chat_message("ai", avatar="./assets/gemini.svg"):
            st.markdown("**Google: Gemini-1.5-flash**")
            st.write(responses[1])  # Gemini ì‘ë‹µ

    with claude_as_col:
        with st.chat_message("ai", avatar="./assets/claude.svg"):
            st.markdown("**Anthropic: Claude-3-5-sonnet**")
            st.write(responses[2])  # Claude ì‘ë‹µ

    with llama_as_col:
        with st.chat_message("ai", avatar="./assets/meta.png"):
            st.markdown("**Meta: Llama3.2-90b-vision**")
            st.write(responses[3])  # LLaMA ì‘ë‹µ

# íƒ­: chatGPT
with gpt_as_tab:
    st.title("ğŸ’¬ openAI: gpt-4o-mini")
    st.caption("ğŸš€ A Streamlit chatbot powered by openAI ChatGPT")
    st.write(responses[0])

# íƒ­: Gemini
with gemini_as_tab:
    st.title("ğŸ’¬ Google: Gemini-1.5-flash")
    st.caption("ğŸš€ A Streamlit chatbot powered by Google Gemini")
    st.write(responses[1])

# íƒ­: Claude
with claude_as_tab:
    st.title("ğŸ’¬ Anthropic: Claude-3-5-sonnet")
    st.caption("ğŸš€ A Streamlit chatbot powered by Anthropic Claude")
    st.write(responses[2])

# íƒ­: llama
with llama_as_tab:
    st.title("ğŸ’¬ Meta: Llama3.2-90b-vision")
    st.caption("ğŸš€ A Streamlit chatbot powered by Meta LLaMA")
    st.write(responses[3])
